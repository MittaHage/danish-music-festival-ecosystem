{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os, re, time, urllib.parse, urllib.request, gzip, json\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "from networkx.algorithms.community import louvain_communities\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import csv\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from adjustText import adjust_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f63613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========  BUILD BIPARTITE GRAPH ==========\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"festival_data.csv\")\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for _, row in df.iterrows():\n",
    "    festival_node = row['festival']\n",
    "    artist_node = row['artist']\n",
    "\n",
    "    G.add_node(festival_node, bipartite=\"festival_year\")\n",
    "    G.add_node(artist_node, bipartite=\"artist\")\n",
    "\n",
    "    G.add_edge(festival_node, artist_node)\n",
    "\n",
    "\n",
    "# Convert graph to JSON serializable structure\n",
    "data = json_graph.node_link_data(G)\n",
    "\n",
    "with open(\"festival_network.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved 'festival_network.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open Network from GitHub JSON\n",
    "\n",
    "base_url = \"missing the json\"\n",
    "\n",
    "# Read JSON directly from GitHub\n",
    "response = urllib.request.urlopen(base_url).read()\n",
    "data = json.loads(response.decode(\"utf-8\"))\n",
    "\n",
    "# Convert to NetworkX graph\n",
    "G = json_graph.node_link_graph(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d9eb70",
   "metadata": {},
   "source": [
    "### basic analysis for bipartie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic analysis\n",
    "\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "\n",
    "festival_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'festival_year']\n",
    "artist_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'artist']\n",
    "\n",
    "print(\"Total nodes:\", num_nodes)\n",
    "print(\"Total edges:\", num_edges)\n",
    "print(\"Festival-Year nodes:\", len(festival_nodes))\n",
    "print(\"Artist nodes:\", len(artist_nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_degrees = [G.degree(n) for n in artist_nodes]\n",
    "festival_degrees = [G.degree(n) for n in festival_nodes]\n",
    "\n",
    "print(\"Average artists per festival:\", sum(festival_degrees) / len(festival_degrees))\n",
    "print(\"Average festivals per artist:\", sum(artist_degrees) / len(artist_degrees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = list(nx.connected_components(G))\n",
    "print(\"Number of connected components:\", len(components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807616d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path_length(G, source=festival_nodes[0])\n",
    "\n",
    "if nx.is_connected(G):\n",
    "    avg_path = nx.average_shortest_path_length(G)\n",
    "    print(\"Average shortest path length:\", avg_path)\n",
    "else:\n",
    "    print(\"Graph is not connected; average shortest path length is undefined.\")\n",
    "\n",
    "\n",
    "# Only works if the graph is connected\n",
    "if not nx.is_connected(G):\n",
    "    print(\"Graph is not fully connected. Using largest connected component.\")\n",
    "    largest_component = max(nx.connected_components(G), key=len)\n",
    "    G_sub = G.subgraph(largest_component)\n",
    "else:\n",
    "    G_sub = G\n",
    "\n",
    "# Calculate all shortest path lengths\n",
    "path_lengths = dict(nx.all_pairs_shortest_path_length(G_sub))\n",
    "\n",
    "# Flatten the distances into a single list (excluding 0 self-distances)\n",
    "all_lengths = []\n",
    "\n",
    "for source in path_lengths:\n",
    "    for target in path_lengths[source]:\n",
    "        if source != target:\n",
    "            all_lengths.append(path_lengths[source][target])\n",
    "\n",
    "# Count occurrences of each path length\n",
    "length_counts = Counter(all_lengths)\n",
    "\n",
    "# ========================\n",
    "# PLOT DISTRIBUTION\n",
    "# ========================\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(length_counts.keys(), length_counts.values())\n",
    "plt.xlabel(\"Shortest Path Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Shortest Path Lengths in Bipartite Network\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff32504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# CENTRALITY MEASURES\n",
    "# ========================\n",
    "\n",
    "# DEGREE CENTRALITY:\n",
    "# For artists → how many festivals they play (ubiquity)\n",
    "# For festivals → size of lineup (scale)\n",
    "degree = dict(G.degree())\n",
    "\n",
    "# BETWEARNESS CENTRALITY:\n",
    "# Measures how often a node lies on shortest paths between others.\n",
    "# This identifies BRIDGES:\n",
    "# Artists = connect different festival clusters\n",
    "# Festivals = connect different artist communities\n",
    "betweenness = nx.betweenness_centrality(G, normalized=True)\n",
    "\n",
    "# CLOSENESS CENTRALITY:\n",
    "# How close a node is to all others.\n",
    "# High value = structurally central and well-positioned.\n",
    "closeness = nx.closeness_centrality(G)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# SPLIT INTO ARTISTS & FESTIVALS\n",
    "# ========================\n",
    "\n",
    "artists = []\n",
    "festivals = []\n",
    "\n",
    "for node, data in G.nodes(data=True):\n",
    "    entry = {\n",
    "        \"node\": node,\n",
    "        \"degree\": degree[node],\n",
    "        \"betweenness\": betweenness[node],\n",
    "        \"closeness\": closeness[node]\n",
    "    }\n",
    "\n",
    "    if data[\"type\"] == \"artist\":\n",
    "        artists.append(entry)\n",
    "    else:\n",
    "        entry[\"festival\"] = data[\"festival\"]\n",
    "        entry[\"year\"] = data[\"year\"]\n",
    "        festivals.append(entry)\n",
    "\n",
    "\n",
    "artist_df = pd.DataFrame(artists)\n",
    "festival_df = pd.DataFrame(festivals)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# SORT & DISPLAY TOP NODES\n",
    "# ========================\n",
    "\n",
    "def show_top(df, metric, title, n=10):\n",
    "    print(\"\\n\" + title)\n",
    "    print(\"-\" * len(title))\n",
    "    display = df.sort_values(by=metric, ascending=False).head(n)\n",
    "    print(display[[\"node\", metric]].to_string(index=False))\n",
    "\n",
    "\n",
    "# ========================\n",
    "# ARTIST ANALYSIS\n",
    "# ========================\n",
    "\n",
    "print(\"\\n================ ARTIST CENTRALITY ================\")\n",
    "\n",
    "# Most frequently booked artists across festivals\n",
    "show_top(\n",
    "    artist_df,\n",
    "    \"degree\",\n",
    "    \"Top Artists by Degree (played most festivals)\",\n",
    ")\n",
    "\n",
    "# Artists that bridge different festival ecosystems\n",
    "show_top(\n",
    "    artist_df,\n",
    "    \"betweenness\",\n",
    "    \"Top Artists by Betweenness (structural bridges)\",\n",
    ")\n",
    "\n",
    "# Artists most centrally embedded in the network\n",
    "show_top(\n",
    "    artist_df,\n",
    "    \"closeness\",\n",
    "    \"Top Artists by Closeness (most network-central)\",\n",
    ")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# SUPERSTAR BRIDGING ARTISTS\n",
    "# ========================\n",
    "\n",
    "print(\"\\n================ SUPERSTAR BRIDGING ARTISTS ================\")\n",
    "print(\"Artists who perform at the most festival-years, acting as structural glue between festivals.\")\n",
    "print(\"High degree here indicates artists most responsible for overlap and homogenisation.\\n\")\n",
    "\n",
    "superstars = artist_df.sort_values(\n",
    "    by=\"degree\",\n",
    "    ascending=False\n",
    ").head(15)\n",
    "\n",
    "print(superstars[[\"node\", \"degree\", \"betweenness\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "# Optional: define a threshold for superstar status\n",
    "threshold = superstars[\"degree\"].mean()\n",
    "\n",
    "print(f\"\\nArtists with degree above superstar threshold ({threshold:.2f} festival-years):\")\n",
    "\n",
    "bridging_elite = artist_df[artist_df[\"degree\"] > threshold]\n",
    "print(bridging_elite[[\"node\", \"degree\"]].to_string(index=False))\n",
    "\n",
    "\n",
    "# ========================\n",
    "# FESTIVAL ANALYSIS\n",
    "# ========================\n",
    "\n",
    "print(\"\\n================ FESTIVAL-YEAR CENTRALITY ================\")\n",
    "\n",
    "# Festivals with the largest lineups\n",
    "show_top(\n",
    "    festival_df,\n",
    "    \"degree\",\n",
    "    \"Festivals by Degree (largest lineups)\",\n",
    ")\n",
    "\n",
    "# Festivals that connect different artist communities\n",
    "show_top(\n",
    "    festival_df,\n",
    "    \"betweenness\",\n",
    "    \"Festivals by Betweenness (structural hubs)\",\n",
    ")\n",
    "\n",
    "# Festivals most central to the ecosystem\n",
    "show_top(\n",
    "    festival_df,\n",
    "    \"closeness\",\n",
    "    \"Festivals by Closeness (most embedded)\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403b8f2",
   "metadata": {},
   "source": [
    "### Projectiled Festival-Year network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ec377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PROJECT TO FESTIVAL-YEAR NETWORK ==========\n",
    "festival_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'festival_year']\n",
    "artist_nodes = [n for n, d in G.nodes(data=True) if d['type'] == 'artist']\n",
    "\n",
    "F = nx.Graph()\n",
    "\n",
    "# Add festival nodes\n",
    "for node in festival_nodes:\n",
    "    F.add_node(node, **G.nodes[node])\n",
    "\n",
    "shared_artist_count = defaultdict(int)\n",
    "\n",
    "# Count shared artists\n",
    "for artist in artist_nodes:\n",
    "    festivals = list(G.neighbors(artist))\n",
    "    for i in range(len(festivals)):\n",
    "        for j in range(i + 1, len(festivals)):\n",
    "            f1, f2 = festivals[i], festivals[j]\n",
    "            shared_artist_count[(f1, f2)] += 1\n",
    "\n",
    "# Add edges with raw weight\n",
    "for (f1, f2), weight in shared_artist_count.items():\n",
    "    F.add_edge(f1, f2, weight=weight)\n",
    "\n",
    "# ========== NORMALISATION (JACCARD SIMILARITY) ==========\n",
    "for f1, f2 in F.edges():\n",
    "    artists_f1 = set(G.neighbors(f1))\n",
    "    artists_f2 = set(G.neighbors(f2))\n",
    "\n",
    "    intersection = len(artists_f1 & artists_f2)\n",
    "    union = len(artists_f1 | artists_f2)\n",
    "\n",
    "    jaccard = intersection / union if union != 0 else 0\n",
    "\n",
    "    F[f1][f2]['jaccard'] = jaccard\n",
    "\n",
    "\n",
    "# ========== SAVE PROJECTED NETWORK ==========\n",
    "projection_data = json_graph.node_link_data(F)\n",
    "\n",
    "with open(\"festival_similarity_network.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(projection_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved festival_similarity_network.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# ========================\n",
    "# GROUP FESTIVAL-YEAR NODES BY FESTIVAL\n",
    "# ========================\n",
    "\n",
    "festival_nodes = {\n",
    "    node: data\n",
    "    for node, data in G.nodes(data=True)\n",
    "    if data[\"type\"] == \"festival_year\"\n",
    "}\n",
    "\n",
    "festival_groups = {}\n",
    "\n",
    "for node, data in festival_nodes.items():\n",
    "    festival = data[\"festival\"]\n",
    "    year = data[\"year\"]\n",
    "    \n",
    "    festival_groups.setdefault(festival, {})[year] = node\n",
    "\n",
    "\n",
    "# ========================\n",
    "# CALCULATE JACCARD OVER TIME\n",
    "# ========================\n",
    "\n",
    "overlap_results = []\n",
    "\n",
    "for festival, years_dict in festival_groups.items():\n",
    "    \n",
    "    # Sort years chronologically\n",
    "    years = sorted(years_dict.keys())\n",
    "    \n",
    "    # Compare all year-pairs for that festival\n",
    "    for y1, y2 in itertools.combinations(years, 2):\n",
    "        \n",
    "        node1 = years_dict[y1]\n",
    "        node2 = years_dict[y2]\n",
    "        \n",
    "        artists_1 = set(G.neighbors(node1))\n",
    "        artists_2 = set(G.neighbors(node2))\n",
    "        \n",
    "        intersection = len(artists_1 & artists_2)\n",
    "        union = len(artists_1 | artists_2)\n",
    "        \n",
    "        jaccard = intersection / union if union != 0 else 0\n",
    "        \n",
    "        overlap_results.append({\n",
    "            \"festival\": festival,\n",
    "            \"year_1\": y1,\n",
    "            \"year_2\": y2,\n",
    "            \"jaccard_overlap\": jaccard,\n",
    "            \"shared_artists\": intersection,\n",
    "            \"total_unique_artists\": union\n",
    "        })\n",
    "\n",
    "\n",
    "# ========================\n",
    "# TURN INTO DATAFRAME FOR DISPLAY\n",
    "# ========================\n",
    "\n",
    "overlap_df = pd.DataFrame(overlap_results)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# SHOW MOST & LEAST STABLE FESTIVALS\n",
    "# ========================\n",
    "\n",
    "print(\"\\n===== Most Stylistically Stable Festivals =====\")\n",
    "print(overlap_df.sort_values(\"jaccard_overlap\", ascending=False)\n",
    "      .head(10)\n",
    "      .to_string(index=False))\n",
    "\n",
    "\n",
    "print(\"\\n===== Most Dramatically Changing Festivals =====\")\n",
    "print(overlap_df.sort_values(\"jaccard_overlap\", ascending=True)\n",
    "      .head(10)\n",
    "      .to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25e101",
   "metadata": {},
   "source": [
    "Compute per-festival temporal overlap metrics (e.g. Jaccard) across years.\n",
    "\n",
    "Compute global network metrics on the projection: degree distribution, clustering, connected components, average path length, maybe community detection (clusters of similar festivals).\n",
    "\n",
    "Optionally compute artist-node degree centrality in bipartite network to identify “superstar bridging artists.”\n",
    "\n",
    "Document lineup sizes (number of artists per festival-year) — for normalization, comparisons, controlling biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca442b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# ========================\n",
    "# RUN COMMUNITY DETECTION\n",
    "# ========================\n",
    "\n",
    "# Use Jaccard similarity as weight for more meaningful clustering\n",
    "communities = greedy_modularity_communities(F, weight=\"jaccard\")\n",
    "\n",
    "print(f\"Number of communities detected: {len(communities)}\\n\")\n",
    "\n",
    "# ========================\n",
    "# DISPLAY COMMUNITIES\n",
    "# ========================\n",
    "\n",
    "for i, community in enumerate(communities, start=1):\n",
    "    print(f\"\\nCommunity {i} (size {len(community)}):\")\n",
    "    for node in community:\n",
    "        festival = F.nodes[node]['festival']\n",
    "        year = F.nodes[node]['year']\n",
    "        print(f\"  - {festival} {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1056ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.quality import modularity\n",
    "\n",
    "mod = modularity(F, communities, weight=\"jaccard\")\n",
    "print(\"Modularity score:\", mod)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
